---
# Documentation: https://wowchemy.com/docs/managing-content/

title: AI-assisted peer review
subtitle: ''
summary: ''
authors:
- A. Checco
- L. Bracciale
- P. Loreti
- S. Pinfield
- G. Bianchi
tags: []
categories: []
date: '2021-01-01'
lastmod: 2022-09-03T10:52:56+02:00
featured: false
draft: false

# Featured image
# To use, add an image named `featured.jpg/png` to your page's folder.
# Focal points: Smart, Center, TopLeft, Top, TopRight, Left, Right, BottomLeft, Bottom, BottomRight.
image:
  caption: ''
  focal_point: ''
  preview_only: false

# Projects (optional).
#   Associate this post with one or more of your projects.
#   Simply enter your project's folder or file name without extension.
#   E.g. `projects = ["internal-project"]` references `content/project/deep-learning/index.md`.
#   Otherwise, set `projects = []`.
projects: []
publishDate: '2022-09-03T08:52:56.406508Z'
publication_types:
- '2'
abstract: The scientific literature peer review workflow is under strain because of
  the constant growth of submission volume. One response to this is to make initial
  screening of submissions less time intensive. Reducing screening and review time
  would save millions of working hours and potentially boost academic productivity.
  Many platforms have already started to use automated screening tools, to prevent
  plagiarism and failure to respect format requirements. Some tools even attempt to
  flag the quality of a study or summarise its content, to reduce reviewers’ load.
  The recent advances in artificial intelligence (AI) create the potential for (semi)
  automated peer review systems, where potentially low-quality or controversial studies
  could be flagged, and reviewer-document matching could be performed in an automated
  manner. However, there are ethical concerns, which arise from such approaches, particularly
  associated with bias and the extent to which AI systems may replicate bias. Our
  main goal in this study is to discuss the potential, pitfalls, and uncertainties
  of the use of AI to approximate or assist human decisions in the quality assurance
  and peer-review process associated with research outputs. We design an AI tool and
  train it with 3300 papers from three conferences, together with their reviews evaluations.
  We then test the ability of the AI in predicting the review score of a new, unobserved
  manuscript, only using its textual content. We show that such techniques can reveal
  correlations between the decision process and other quality proxy measures, uncovering
  potential biases of the review process. Finally, we discuss the opportunities, but
  also the potential unintended consequences of these techniques in terms of algorithmic
  bias and ethical concerns. © 2021, The Author(s).
publication: '*Humanities and Social Sciences Communications*'
doi: 10.1057/s41599-020-00703-8
links:
- name: URL
  url: https://www.scopus.com/inward/record.uri?eid=2-s2.0-85099744917&doi=10.1057%2fs41599-020-00703-8&partnerID=40&md5=d8471cff9ebd13fb79bac0c6ce627511
---
